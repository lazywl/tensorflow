{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0444444\n",
      "0.424074\n",
      "0.575926\n",
      "0.65\n",
      "0.687037\n",
      "0.714815\n",
      "0.737037\n",
      "0.751852\n",
      "0.762963\n",
      "0.766667\n",
      "0.781482\n",
      "0.787037\n",
      "0.798148\n",
      "0.8\n",
      "0.807407\n",
      "0.812963\n",
      "0.818519\n",
      "0.822222\n",
      "0.824074\n",
      "0.824074\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "#mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None, ):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(x_test,y_test):\n",
    "    global predict\n",
    "    y_predict = sess.run(predict,feed_dict={xs:x_test})\n",
    "    correct_predict = tf.equal(tf.arg_max(y_predict,1),tf.arg_max(y_test,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    return sess.run(accuracy) #, feed_dict={xs: x_test, ys: y_test}\n",
    "\n",
    "    \n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32,[None,64])\n",
    "ys = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "\n",
    "# add output layer\n",
    "l1 = add_layer(xs,64,50,activation_function=tf.nn.tanh)\n",
    "predict = add_layer(l1,50,10,activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(predict),reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    #batch_x,batch_y = mnist.train.next_batch(100)\n",
    "    sess.run(train_step,feed_dict={xs:X_train,ys:y_train})\n",
    "    if i % 50 == 0:\n",
    "         print compute_accuracy(X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
